# **High Level Design: Morphogenetic Training Platform - Esper**

**Version:** 0.1a
**Status:** Drafting
**Date:** 23 June 2025
**Author:** John Morrissey, Gemini AI

## **1. Executive Summary**

Esper is an autonomous, self-optimising machine-learning infrastructure that addresses a fundamental challenge in modern AI: the static nature of neural network architectures. Esper is designed to **continuously detect computational bottlenecks inside a running neural network and patch them in-situ with specialised, novel sub-networks (“Blueprints”)**. This process occurs dynamically during the training lifecycle, transforming the model from a rigid structure into an adaptable, evolving entity.

The platform is a synthesis of three synergistic subsystems, each with a distinct role, designed to create a complete, self-improving ecosystem. This separation of concerns ensures robustness, scalability, and clarity of purpose.

|

| Subsystem | Component(s) | Role | Core Problem Solved | Primary Consequence |  
| The Operator | Kasmina | Low-level execution, safe grafting | Precise, neuron-level adaptation without destabilising the host model. | Enables surgical interventions on a live network, ensuring that changes are both targeted and integrated smoothly without causing training collapse. |  
| The Controller | Tamiyo | Global orchestration & strategic policy | Choosing when, where, and what to adapt for maximum task-level benefit. | Provides the strategic intelligence to allocate finite adaptation resources effectively, ensuring efforts are focused on the most critical bottlenecks. |  
| The Architect | Karn, Urza & Urabrask | Continuous blueprint design & testing | Generating and battle-testing new, innovative solutions so the system never stops improving. | Creates a perpetual engine of innovation, preventing architectural stagnation and ensuring the library of available solutions grows more powerful over time. |  
Together, these components deliver a platform that not only improves model quality when training plateaus but also learns from every deployment to get better over time, all while respecting hardware and safety constraints. This document serves as the single source of truth for the entire Esper system, integrating the specifications of its constituent parts to provide a unified architectural vision.

## **2. The Esper Philosophy: Three Interlocking Loops**

The Esper platform's architecture is best understood as three interlocking loops operating at different timescales. This multi-loop design creates a powerful flywheel effect, where operational adaptations fuel strategic learning, which in turn drives fundamental innovation.

graph TD  
    subgraph "Loop 1: The Online Adaptation Loop (Real-time, per-epoch)"  
        A1[Kasmina: Pushes rich, per-chunk<br>health telemetry every epoch] --> A2{Tamiyo: Continuously analyzes telemetry<br>and global metrics, detects plateau};  
        A2 --> A3[Tamiyo: Queries Urza Library for<br>optimal hardware-aware blueprint];  
        A3 --> A4[Tamiyo: Issues Germinate Command<br>with chosen blueprint & grafting strategy];  
        A4 --> A5[Kasmina: Executes the multi-stage<br>Seed Lifecycle safely];  
        A5 -- Publishes Final Status Report (FOSSILIZED/CULLED/ROLLBACK) --> A6{Tamiyo: Generates FieldReport<br>with rich performance metrics for Karn};
    end

    subgraph "Loop 2: The Offline R&D Loop (Continuous, asynchronous)"  
        B1[Karn: Designs novel<br>Blueprint architectures] --> B2[Urabrask: Subjects candidates to<br>a gauntlet of tests & risk scoring];  
        B2 --> B3[Urza Library: Stores certified,<br>battle-tested blueprints with rich metadata];  
    end

    subgraph "Loop 3: The Outer Reinforcement Loop (Learning, long-term)"  
        A6 -- Real-world outcome report serves as<br>a reward/penalty signal --> B1;  
    end

    B3 -- Provides a menu of certified solutions --> A3;

* **Loop 1: The Training Loop (Kasmina and Tamiyo):** This is the live, operational loop that executes on a per-epoch timescale. It is the system's reactive core. **Kasmina** instances, embedded in the host network, function as sensors, constantly pushing detailed health telemetry. **Tamiyo**, the controller, acts as the central nervous system, analyzing this stream of data. Upon detecting a performance plateau, she diagnoses the root cause, queries the **Urza** library for the best available **Blueprint**, and commands the appropriate Kasmina seed to begin its adaptation lifecycle. This is the "fix it now" loop, designed for immediate, tactical response to emergent problems.  
* **Loop 2: The R&D Loop (Karn and Urabrask):** This is the innovation engine that runs continuously and asynchronously in the background. It ensures the system's toolkit is always expanding. **Karn**, the generative architect, designs novel blueprint architectures using advanced Neural Architecture Search (NAS) techniques. These candidates are then submitted to **Urabrask**, a brutal testing forge that benchmarks them for performance, stability, and novelty. Only blueprints that pass this gauntlet are certified and added to the **Urza** library, ensuring a steady supply of high-quality, reliable solutions for Tamiyo to draw upon. Once a blueprint is certified, it becomes available to Tamiyo when she needs to address a performance issue in the live system. This loop is focused on long-term innovation, ensuring that the system can adapt to new challenges and opportunities as they arise. [TODO: How does Karn and Tamiyo continuously train on when to use new blueprints without overfitting? Some sort of rotating set of loras?]

* **Loop 3: The Outer Reinforcement Loop (Kasima, Tamiyo and Karn):** This is the strategic learning loop that makes the entire system self-improving, operating over longer timescales. The final outcome of an adaptation in the live system (FOSSILIZED for success, CULLED for failure, ROLLBACK for catastrophic failure) is packaged into a rich report and sent back to **Karn**. This real-world feedback serves as a powerful reinforcement signal, teaching Karn which architectural patterns succeed in which contexts. This loop closes the circle, transforming Esper from a merely adaptive system into a genuinely learning one.

### **3. Component Architecture Deep Dive**

#### **3.1. Kasmina (The Operator)**

Kasmina is the foundational layer responsible for low-level execution. It is not a single entity but an architecture implemented by many `KasminaSeed` modules embedded within a host network. It is the "hands" of the system, performing the delicate surgery on the live model.

* **Granularity:** Kasmina operates in a "Chunked" mode, allowing an operator to define the granularity of adaptation. This ranges from coarse (e.g., one seed per layer) to ultra-fine. In its ultra-fine mode, the `seeds_per_layer` parameter is set equal to the layer's `hidden_dim`, resulting in a `chunk_size` of 1. This provides maximum diagnostic precision by assigning one seed to monitor each individual value in the activation tensor, which is ideal for detecting issues like "dead neurons". This flexibility allows for a trade-off between precision and computational overhead, making the system viable for both small edge models and large-scale networks.
* **Data Flow:** It uses a safe and predictable split -> process -> concatenate data flow. A layer's activation tensor is split into non-overlapping chunks, each chunk is processed in isolation by its corresponding seed, and the results are reassembled. This ensures that the actions of one seed do not interfere with another during the forward pass.
* **Telemetry:** Each seed generates a rich, multi-metric health signal (chunk_variance, dead_node_ratio, activity_entropy, etc.). This goes far beyond a simple "is it working?" signal, providing a multi-dimensional diagnostic vector that Tamiyo can use to understand the *nature* of a bottleneck (e.g., a "dead" chunk vs. a "redundant" one).
* **Lifecycle Execution:** Kasmina is responsible for rigorously executing the authoritative 11-stage seed lifecycle. This includes managing the initial self-supervised TRAINING, the critical GRAFTING phase, and the final task-aligned FINE-TUNING, ensuring every step is performed correctly.
* **Grafting Strategies:** It employs a set of pluggable grafting strategies (e.g., FixedRamp, DriftControlled). These strategies dictate how a new blueprint is blended into the network, providing crucial control over stability. A DriftControlled strategy, for instance, will automatically pause the integration if it detects that the host model is becoming unstable, preventing a catastrophic failure.

#### **3.2. Tamiyo (The Controller)**

Tamiyo is the strategic brain of the live system, responsible for the wisdom of every operation. Where Kasmina provides the *how*, Tamiyo provides the *why*.

* **Strategic Oversight:** Tamiyo is responsible for the overall health of the network. It monitors global metrics and can initiate adaptations based on long-term trends rather than immediate telemetry spikes. This strategic oversight ensures that the system remains robust and capable of handling evolving workloads.
* **Neural Network:** The architecture is a trained neural network. It will learn its sophisticated control policy through reinforcement learning, discovering complex correlations between telemetry patterns, blueprint choices, and final outcomes that would be impossible for a human to specify. This allows Tamiyo to adapt dynamically to new situations, learning from past adaptations to make better decisions in the future.
* **Governance:** Tamiyo is responsible for enforcing the governance policies defined in the Urza library. It ensures that only blueprints with an appropriate risk band (wep_band) are deployed into sensitive production environments. This governance layer is critical for maintaining the integrity and reliability of the system, preventing high-risk adaptations from destabilizing the host model.
* **Queue Management:** To maintain stability, the system typically only allows one adaptation to be in an active training phase at a time (although the number of seeds concurrently training is customisable). Tamiyo can issue multiple germinate commands, which place seeds into a GERMINATED waiting queue. Critically, Tamiyo retains the ability to "call back" a command if a node's health improves on its own, freeing up the adaptation slot for a more pressing issue.  
* **Policy Engine:** Tamiyo's policy engine is the heart of its decision-making process. It uses a combination of heuristics and learned policies to determine when to adapt, which blueprint to use, and how to configure the grafting strategy. This engine is trained on historical adaptation data, allowing it to make informed decisions that balance risk and reward.
* **Safety Shield:** Platform safety is ensured through a multi-layered framework, beginning with a deterministic **Shield** in the Tamiyo controller that enforces hard constraints on every proposed adaptation. This is followed by a learned policy and a disciplined canary deployment pipeline to manage risk while allowing for innovation.

#### **3.3. Karn (The Architect)**

Karn is the generative engine at the heart of the R&D loop, responsible for all architectural innovation. It is the source of Esper's long-term evolution.

* **Neural Architecture Search (NAS):** Karn is implemented as a generative model (e.g., a GNN or Transformer) that designs novel Blueprint architectures from the ground up. It explores the vast space of possible sub-networks to find new solutions.  
* **Reinforcement Learning:** Karn's most critical feature is its ability to learn from real-world outcomes. It receives FieldReport  objects from Tamiyo detailing the success or failure of its previous designs in a live environment. This feedback serves as a reward or penalty, refining its generative process to avoid architectural anti-patterns and favor patterns that have proven successful.  
* **Holistic Design:** Karn's role is deeper than just proposing new network graphs. It co-generates appropriate self-supervised training protocols for its blueprints, ensuring they can be effectively trained by Kasmina. It is also responsible for maintaining the "Genetic Diversity" of the Urza library, proactively injecting "exotic" seeds if the library becomes too homogenous and risks stagnating.
* **Collaboration with Urabrask:** Karn works closely with Urabrask to ensure that its blueprints are battle-tested before being added to the Urza library. This collaboration ensures that only high-quality, reliable designs are made available for Tamiyo to use in live adaptations.

#### **3.4. Urabrask & Urza (The Forge & The Library)**

These two components form the quality control, governance, and storage backbone of the R&D plane. They ensure that all innovation is safe, reliable, and ready for deployment.

* **Urabrask (The Crucible):** An automated evaluation forge that stress-tests every candidate blueprint from Karn.  
  * **Risk Scoring:** It goes beyond simple pass/fail tests. It quantifies risk by generating a detailed **Weighted Evaluation Profile (WEP)**, calculating a final `risk_score`, and assigning a `conf_level` ('High', 'Moderate', or 'Speculative') that governs its deployment path. A Speculative blueprint, for example, might require manual human oversight before Tamiyo is permitted to deploy it or might be excluded via a configuration setting.  
* **Urza (The Library):** The immutable, single source of truth for every certified blueprint.  
  * **Universal Schema:** Urza defines a strict, universal metadata schema that every blueprint must adhere to. This schema is the contract that binds the system together, containing performance metrics from Urabrask, a cryptographic hash (sha256) for integrity, licensing information, and novelty scores.  
  * **Deployment Governance:** The conf_level stored in Urza acts as a formal safety and reliability gate. Tamiyo's policy engine is hard-coded to respect these gates, ensuring that experimental or high-risk blueprints are not deployed into sensitive production environments without the proper approvals.

#### **3.5. Tolaria (The Trainer)**

Tolaria is the foundational training environment for the Esper Morphogenetic Platform. It functions as an intelligent, state-aware training academy that orchestrates the entire learning process. Rather than being a passive script, Tolaria provides the structured, temporal context of epochs and steps within which the host model learns and all other Esper components operate. It is the master process that provides the stability required for the dynamic adaptations orchestrated by Tamiyo and executed by Kasmina.

* **Epoch Lifecycle Management**: Tolaria owns and manages the master training and validation loops. It loads data, executes the forward and backward passes, and serves as the "heartbeat" for the entire Esper system by establishing a predictable operational cadence.
* **Morphogenetic Integration Hook**: Tolaria's most critical function is its end-of-epoch hook, which serves as the primary integration point for the adaptive systems. At the conclusion of each validation loop, Tolaria performs two key actions:
    1. It assembles a `SystemStatePacket`, gathering global performance metrics (e.g., `validation_loss`, `validation_accuracy`) and hardware context.
    2. It invokes the Tamiyo controller by calling the `tamiyo.step()` method, passing the system state packet and ceding control for all strategic adaptation decisions.
* **Dynamic Optimizer Management**: Tolaria is equipped with a `DynamicOptimizerManager` to handle the changing architecture of the host model. When Tamiyo signals that a new blueprint has been successfully and permanently integrated (`FOSSILIZED`), Tolaria is responsible for scanning the model, identifying the new parameters, and rebuilding the optimizer to ensure the new capacity is trained in subsequent epochs.
* **State Persistence and Rollback**: Tolaria owns the checkpointing system. It is responsible for saving the state of not only the host model but also the `TamiyoController` to ensure their states are synchronized. If Tamiyo triggers an `emergency_rollback_required` signal due to catastrophic instability, Tolaria executes the rollback, restoring both the model and the controller to their last known-good checkpoint before proceeding.

### **4. The Canonical Seed Lifecycle**

The seed lifecycle is the core process model for every adaptation, ensuring safety and effectiveness. It is orchestrated by Tamiyo and executed by Kasmina. This multi-stage process is designed to prevent unstable components from ever impacting the main network and to ensure that only beneficial adaptations are made permanent.

The authoritative definition of the seed lifecycle can be found in Section 9 of the Kasmina detailed design document, which provides a comprehensive overview of the lifecycle stages.  This lifecycle is the backbone of the Esper system, ensuring that every adaptation is made with care, precision, and a focus on long-term stability. Each stage has been designed to mitigate specific risks, ensuring that the system can adapt dynamically without compromising the integrity of the host model.

### **5. Conclusion**

Esper represents a holistic, end-to-end system for the autonomous optimization and evolution of neural networks. By tightly integrating the real-time operational loop of **Kasmina** and **Tamiyo** with the continuous, innovation loop of **Karn** and **Urabrask**, it creates a powerful flywheel effect. The system doesn't just fix problems—it learns from them, designing increasingly better and more specialized solutions over time. The clear separation of concerns between operator, controller, and innovator, combined with robust safety mechanisms and a comprehensive governance framework, provides a solid foundation for building a truly next-generation machine learning infrastructure. Esper is architected not just to build better models today, but to discover how to build the superior models of tomorrow.

### **6. Project Glossary**

* **Blueprint**: A self-contained, instantiable neural network module with a standardized interface and metadata schema, designed to be integrated into a host model by Kasmina to address a specific computational bottleneck.
* **Germination**: The process of initializing a new blueprint for training.
* **Grafting**: The integration of a trained blueprint into the main model.
* **Fossilization**: The state of a blueprint that has demonstrated global improvement and is permanently frozen.
* **Culling**: The deactivation of a blueprint that fails at any gate.
* **Kasmina**: The operator responsible for low-level execution and safe grafting.
* **Tamiyo**: The controller that orchestrates adaptations and strategic policy decisions.
* **Karn**: The architect responsible for generating novel blueprint designs.
* **Urabrask**: The crucible that evaluates and certifies blueprints.
* **Urza**: The library that stores certified blueprints and their metadata.
* **FieldReport**: A report generated by Tamiyo that contains the final status and rich performance metrics of a blueprint after its adaptation lifecycle.
* **Weighted Evaluation Profile (WEP):** A comprehensive, structured dictionary of performance, stability, and novelty metrics generated by Urabrask during blueprint evaluation.
* **Risk Score:** A single, normalized floating-point number calculated from the `WEP` that represents a blueprint's overall deployment risk.
* **Confidence Level (`conf_level`):** The human-readable confidence level ('High', 'Moderate', 'Speculative') assigned to a blueprint based on its `risk_score`.
